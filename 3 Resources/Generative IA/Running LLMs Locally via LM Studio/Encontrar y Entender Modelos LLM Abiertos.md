
---

![[Pasted image 20250811161152.png]]

Entonces, ¿cuál es la idea detrás de estos modelos abiertos y qué son exactamente? Bueno, la idea es que estos son modelos que puedes usar esencialmente de forma gratuita. Puedes, por ejemplo, ejecutarlos localmente. Tienes acceso a los parámetros entrenados, por así decirlo, y por lo tanto, puedes usar estos modelos sin pagar por un servicio como ChatGPT.

Ahora, lo importante a tener en cuenta es que muchos modelos, especialmente todos los modelos realmente buenos que son utilizados detrás de escena por ChatGPT o Google o xAI, no son de código abierto. No tienes acceso a ellos. No puedes ejecutarlos localmente. Pero hay muchas alternativas útiles, y Hugging Face, huggingface.co, es un gran lugar para explorar todos esos modelos de código abierto que existen. Es la página más popular para hacer eso, para encontrar modelos de código abierto. Es la página donde, esencialmente, todos los proveedores que crean modelos abiertos comparten esos modelos. Y adjunto, encontrarás un enlace a su página de modelos, donde encontrarás una lista actualizada de todos los modelos que se comparten allí. Y es allí donde encontrarás, por ejemplo, cosas como DeepSeq R1 o los modelos Google Gemma, porque aunque Google tiene sus propios modelos propietarios que son utilizados por su servicio Gemini, también publican algunos modelos de código abierto llamados Gemma, que no deben confundirse con los modelos Gemini. Gemma es la versión abierta y gratuita. Gemini es por lo que pagas.

Y si exploras esos modelos, puedes aprender más sobre ellos, más sobre sus capacidades, y típicamente también algunas estadísticas sobre ellos y aprender, por ejemplo, cómo se desempeñan en varios benchmarks. También puedes visitar sitios como lmarena.ai, que tiene un ranking que se actualiza continuamente, donde también puedes encontrar varios modelos clasificados por sus capacidades. Ahora, por supuesto, siempre debes tener un poco de cuidado con eso. Algunos modelos pueden hacerlo muy bien en algunos benchmarks y ser realmente malos en otros escenarios. Los modelos también podrían estar optimizados para hacerlo muy bien en ciertos benchmarks. Pero, no obstante, estas diferentes estadísticas y también esta página de ranking aquí pueden darte una idea de cuán bien se desempeña un cierto modelo. Y lo que es genial sobre esta página de ranking aquí, por ejemplo, es que lista tanto modelos propietarios como de código abierto. Puedes saber qué es qué por la licencia aquí. Y, por ejemplo, en ese ranking aquí, en el momento en que estoy grabando esto, puedo encontrar los modelos DeepSeq y también el modelo Gemma aquí, que son, nuevamente, modelos de código abierto que puedes ejecutar localmente, por ejemplo. Y como puedes ver, aquí no lo están haciendo tan mal. El modelo Gemma de Google, por ejemplo, en este ranking aquí, lo hace mejor que el modelo o3-mini-high de OpenAI, que es un modelo propietario que solo se puede acceder a través de ChatGPT.

![[Pasted image 20250811161255.png]]

Así que esa es la situación con esos modelos de código abierto. Pueden ser bastante capaces, y puedes usarlos de forma gratuita. Y en páginas como Hugging Face, puedes explorar una plétora de modelos que están disponibles. También vale la pena señalar que, de hecho, la mayoría de los modelos de código abierto son más pequeños, lo que significa que tienen menos parámetros que los modelos propietarios más capaces. Y en general, ser más pequeño, tener menos parámetros significa ser menos capaz. Hay una razón por la cual en este ranking, por ejemplo, los mejores modelos son los propietarios. Aunque también señalaré que cuando se lanzó DeepSeq R1 en enero de 2025, sacudió el mundo de los modelos de lenguaje grande porque era un modelo de lenguaje grande muy capaz con muchos parámetros, y por lo tanto, en realidad era mejor que muchos modelos propietarios. Así que no es una regla estricta, pero en general, estos modelos de código abierto son menos capaces, y especialmente los modelos que puedes ejecutar localmente porque, como se mencionó antes, estos modelos de lenguaje grande, sin importar si son de código abierto o no, será difícil ejecutarlos localmente debido a su tamaño. Pero volveré a eso más tarde. Depende de tu caso de uso, sin embargo, si esta parte menos capaz es realmente un problema para ti, porque para muchas tareas, un modelo pequeño que se ejecute localmente puede ser igual de bueno o incluso mejor que ChatGPT y otros. Por ejemplo, si estás resumiendo algún artículo, si estás tratando de extraer datos de algún artículo o de algún archivo CSV, o si tienes tareas donde necesitas cargar conocimiento local en la ventana de contexto y luego hacer preguntas relacionadas con eso o hacer algo con ese conocimiento, en tales situaciones, un modelo de código abierto que se ejecute localmente podría ser lo suficientemente bueno o incluso mejor que ChatGPT y otros porque eliminas la latencia, eliminas los aspectos de privacidad de datos, y podría ofrecerte resultados perfectos. Y por eso considerar usar modelos que se ejecuten localmente puede valer la pena.

---

**Resumen:**

El documento explica la idea detrás de los modelos de lenguaje abiertos (LLMs) y su disponibilidad. Estos modelos pueden ser utilizados de forma gratuita y ejecutados localmente, a diferencia de muchos modelos propietarios que no están disponibles para el público. Hugging Face es mencionado como un recurso clave para explorar modelos de código abierto, donde se pueden encontrar modelos como DeepSeq R1 y Gemma de Google. Aunque los modelos de código abierto suelen ser más pequeños y menos capaces que los modelos propietarios, pueden ser útiles para tareas específicas, como resumir artículos o extraer datos. La elección de un modelo local puede ser beneficiosa en términos de latencia y privacidad de datos.

---
### Notas

| *Huggingface* | https://huggingface.co/models  |
| ------------- | ------------------------------ |
| *lmarena.ai*  | https://lmarena.ai/leaderboard |


