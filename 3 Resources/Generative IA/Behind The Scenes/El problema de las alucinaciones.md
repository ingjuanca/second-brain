
---

### âš ï¸Â **Resumen: El problema de las alucinaciones en los modelos de lenguaje**

Este documento aborda uno de los desafÃ­os mÃ¡s conocidos y persistentes en los modelos de lenguaje: lasÂ **alucinaciones**.

---

### ğŸ§ Â **Â¿QuÃ© son las alucinaciones?**

![[Pasted image 20250709213857.png]]

- Los modelos de lenguajeÂ **predicen tokens**Â (fragmentos de texto) basados en lo que es mÃ¡s probable,Â **no en lo que es verdadero**.
- Esto significa que puedenÂ **inventar informaciÃ³n**Â que suena creÃ­ble pero es falsa.

---

### ğŸ›¡ï¸Â **Â¿QuÃ© se ha hecho para reducirlas?**

- Los proveedores de modelos han implementadoÂ **â€œguardrailsâ€**Â (barreras de seguridad) para reducir las alucinaciones:
    - **Filtrado de preguntas**Â mediante otras IA o reglas especÃ­ficas.
    - **Entrenamiento con ejemplos**Â donde el modelo aprende a responder con frases como:  
        _â€œLo siento, no puedo responder esoâ€_Â oÂ _â€œNo tengo esa informaciÃ³nâ€_.

---

### ğŸ“‰Â **Â¿Funcionan estas medidas?**

- SÃ­, hanÂ **reducido la frecuencia**Â de alucinaciones.
- PeroÂ **no las eliminan por completo**. El modelo aÃºn puede generar respuestas incorrectas.

---

### âœ…Â **Recomendaciones clave**

- **Nunca asumas que la respuesta es 100% correcta.**
- **Verifica la informaciÃ³n**, especialmente si se trata de temas importantes como:
    - Asuntos legales.
    - Declaraciones de impuestos.
    - InformaciÃ³n mÃ©dica o financiera.

---

### ğŸ“ŒÂ **ConclusiÃ³n**

Las alucinaciones siguen siendo unaÂ **limitaciÃ³n crÃ­tica**Â de los modelos de lenguaje. Aunque han mejorado,Â **la verificaciÃ³n humana sigue siendo esencial**.

---